{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
        "### Due: October 10 at 11:59pm\n",
        "\n",
        "### Name: Carissa Chung"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "## Part 1: Classification (14.5 marks total)\n",
        "\n",
        "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3c6fc8",
      "metadata": {
        "id": "7e3c6fc8"
      },
      "source": [
        "### Step 0: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "33f86925",
      "metadata": {
        "id": "33f86925"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "### Step 1: Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "33583c67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33583c67",
        "outputId": "6c2951a4-71f9-452d-8232-afc37ab1c4db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of X is: 262200\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4600 entries, 0 to 4599\n",
            "Data columns (total 57 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   word_freq_make              4600 non-null   float64\n",
            " 1   word_freq_address           4600 non-null   float64\n",
            " 2   word_freq_all               4600 non-null   float64\n",
            " 3   word_freq_3d                4600 non-null   float64\n",
            " 4   word_freq_our               4600 non-null   float64\n",
            " 5   word_freq_over              4600 non-null   float64\n",
            " 6   word_freq_remove            4600 non-null   float64\n",
            " 7   word_freq_internet          4600 non-null   float64\n",
            " 8   word_freq_order             4600 non-null   float64\n",
            " 9   word_freq_mail              4600 non-null   float64\n",
            " 10  word_freq_receive           4600 non-null   float64\n",
            " 11  word_freq_will              4600 non-null   float64\n",
            " 12  word_freq_people            4600 non-null   float64\n",
            " 13  word_freq_report            4600 non-null   float64\n",
            " 14  word_freq_addresses         4600 non-null   float64\n",
            " 15  word_freq_free              4600 non-null   float64\n",
            " 16  word_freq_business          4600 non-null   float64\n",
            " 17  word_freq_email             4600 non-null   float64\n",
            " 18  word_freq_you               4600 non-null   float64\n",
            " 19  word_freq_credit            4600 non-null   float64\n",
            " 20  word_freq_your              4600 non-null   float64\n",
            " 21  word_freq_font              4600 non-null   float64\n",
            " 22  word_freq_000               4600 non-null   float64\n",
            " 23  word_freq_money             4600 non-null   float64\n",
            " 24  word_freq_hp                4600 non-null   float64\n",
            " 25  word_freq_hpl               4600 non-null   float64\n",
            " 26  word_freq_george            4600 non-null   float64\n",
            " 27  word_freq_650               4600 non-null   float64\n",
            " 28  word_freq_lab               4600 non-null   float64\n",
            " 29  word_freq_labs              4600 non-null   float64\n",
            " 30  word_freq_telnet            4600 non-null   float64\n",
            " 31  word_freq_857               4600 non-null   float64\n",
            " 32  word_freq_data              4600 non-null   float64\n",
            " 33  word_freq_415               4600 non-null   float64\n",
            " 34  word_freq_85                4600 non-null   float64\n",
            " 35  word_freq_technology        4600 non-null   float64\n",
            " 36  word_freq_1999              4600 non-null   float64\n",
            " 37  word_freq_parts             4600 non-null   float64\n",
            " 38  word_freq_pm                4600 non-null   float64\n",
            " 39  word_freq_direct            4600 non-null   float64\n",
            " 40  word_freq_cs                4600 non-null   float64\n",
            " 41  word_freq_meeting           4600 non-null   float64\n",
            " 42  word_freq_original          4600 non-null   float64\n",
            " 43  word_freq_project           4600 non-null   float64\n",
            " 44  word_freq_re                4600 non-null   float64\n",
            " 45  word_freq_edu               4600 non-null   float64\n",
            " 46  word_freq_table             4600 non-null   float64\n",
            " 47  word_freq_conference        4600 non-null   float64\n",
            " 48  char_freq_;                 4600 non-null   float64\n",
            " 49  char_freq_(                 4600 non-null   float64\n",
            " 50  char_freq_[                 4600 non-null   float64\n",
            " 51  char_freq_!                 4600 non-null   float64\n",
            " 52  char_freq_$                 4600 non-null   float64\n",
            " 53  char_freq_#                 4600 non-null   float64\n",
            " 54  capital_run_length_average  4600 non-null   float64\n",
            " 55  capital_run_length_longest  4600 non-null   int64  \n",
            " 56  capital_run_length_total    4600 non-null   int64  \n",
            "dtypes: float64(55), int64(2)\n",
            "memory usage: 2.0 MB\n",
            "\n",
            "The size of y is: 4600\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 4600 entries, 0 to 4599\n",
            "Series name: is_spam\n",
            "Non-Null Count  Dtype\n",
            "--------------  -----\n",
            "4600 non-null   int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 36.1 KB\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import spam dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_spam\n",
        "X, y = load_spam()\n",
        "\n",
        "# TO DO: Print size and type of X and y\n",
        "print(\"The size of X is:\", X.size)\n",
        "X.info()\n",
        "\n",
        "print(\"\\nThe size of y is:\", y.size)\n",
        "y.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "### Step 2: Data Processing (1.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4e7204f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e7204f5",
        "outputId": "4089141a-b8c4-44c2-92b3-2e148febb543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word_freq_make                0\n",
            "word_freq_address             0\n",
            "word_freq_all                 0\n",
            "word_freq_3d                  0\n",
            "word_freq_our                 0\n",
            "word_freq_over                0\n",
            "word_freq_remove              0\n",
            "word_freq_internet            0\n",
            "word_freq_order               0\n",
            "word_freq_mail                0\n",
            "word_freq_receive             0\n",
            "word_freq_will                0\n",
            "word_freq_people              0\n",
            "word_freq_report              0\n",
            "word_freq_addresses           0\n",
            "word_freq_free                0\n",
            "word_freq_business            0\n",
            "word_freq_email               0\n",
            "word_freq_you                 0\n",
            "word_freq_credit              0\n",
            "word_freq_your                0\n",
            "word_freq_font                0\n",
            "word_freq_000                 0\n",
            "word_freq_money               0\n",
            "word_freq_hp                  0\n",
            "word_freq_hpl                 0\n",
            "word_freq_george              0\n",
            "word_freq_650                 0\n",
            "word_freq_lab                 0\n",
            "word_freq_labs                0\n",
            "word_freq_telnet              0\n",
            "word_freq_857                 0\n",
            "word_freq_data                0\n",
            "word_freq_415                 0\n",
            "word_freq_85                  0\n",
            "word_freq_technology          0\n",
            "word_freq_1999                0\n",
            "word_freq_parts               0\n",
            "word_freq_pm                  0\n",
            "word_freq_direct              0\n",
            "word_freq_cs                  0\n",
            "word_freq_meeting             0\n",
            "word_freq_original            0\n",
            "word_freq_project             0\n",
            "word_freq_re                  0\n",
            "word_freq_edu                 0\n",
            "word_freq_table               0\n",
            "word_freq_conference          0\n",
            "char_freq_;                   0\n",
            "char_freq_(                   0\n",
            "char_freq_[                   0\n",
            "char_freq_!                   0\n",
            "char_freq_$                   0\n",
            "char_freq_#                   0\n",
            "capital_run_length_average    0\n",
            "capital_run_length_longest    0\n",
            "capital_run_length_total      0\n",
            "dtype: int64\n",
            "\n",
            " 0\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "print(X.isna().sum())\n",
        "print(\"\\n\", y.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a489285a",
      "metadata": {
        "id": "a489285a"
      },
      "source": [
        "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f9bc4a23",
      "metadata": {
        "id": "f9bc4a23"
      },
      "outputs": [],
      "source": [
        "# TO DO: Create X_small and y_small\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# make separate subset of data\n",
        "X_large, X_small, y_large, y_small = train_test_split(X, y, test_size=0.05, random_state=0, stratify=y)\n",
        "# try with stratify=y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Implement the machine learning model with three different datasets:\n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "T4TucNRC2lmC",
      "metadata": {
        "id": "T4TucNRC2lmC"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "hw81fJ4-28Y3",
      "metadata": {
        "id": "hw81fJ4-28Y3"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
        "linear_model_001 = LogisticRegression(max_iter=2000).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "or1VMO9F3hxW",
      "metadata": {
        "id": "or1VMO9F3hxW"
      },
      "outputs": [],
      "source": [
        "X_2col = X.iloc[:, 0:2]\n",
        "X_2col_train, X_2col_val, y2_train, y2_val = train_test_split(X_2col, y, random_state=0)\n",
        "linear_model_002 = LogisticRegression(max_iter=2000).fit(X_2col_train, y2_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "1FTjSWJ328Pi",
      "metadata": {
        "id": "1FTjSWJ328Pi"
      },
      "outputs": [],
      "source": [
        "X_small_train, X_small_val, y_small_train, y_small_val = train_test_split(X_small, y_small, random_state=0)\n",
        "linear_model_003 = LogisticRegression(max_iter=2000).fit(X_small_train, y_small_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89f3d84",
      "metadata": {
        "id": "b89f3d84"
      },
      "source": [
        "### Step 4: Validate Model\n",
        "\n",
        "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352106a3",
      "metadata": {
        "id": "352106a3"
      },
      "source": [
        "### Step 5: Visualize Results (4 marks)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "d6dbd7f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 1: X and y\n",
            "Training score:  0.928695652173913\n",
            "Validation score:  0.9373913043478261\n",
            "Test 2: First 2 cols of X and y\n",
            "Training score:  0.6084057971014493\n",
            "Validation score:  0.6130434782608696\n",
            "Test 3: X_small and y_small\n",
            "Training score:  0.936046511627907\n",
            "Validation score:  0.8620689655172413\n"
          ]
        }
      ],
      "source": [
        "Training = []\n",
        "Validation = []\n",
        "\n",
        "# Test 1: X and y\n",
        "Training.append(linear_model_001.score(X_train, y_train))\n",
        "Validation.append(linear_model_001.score(X_val, y_val))\n",
        "\n",
        "print(\"Test 1: X and y\")\n",
        "print(\"Training score: \", Training[0])\n",
        "print(\"Validation score: \", Validation[0])\n",
        "\n",
        "# Test 2: Only first two columns of X and y\n",
        "Training.append(linear_model_002.score(X_2col_train, y2_train))\n",
        "Validation.append(linear_model_002.score(X_2col_val, y2_val))\n",
        "\n",
        "print(\"Test 2: First 2 cols of X and y\")\n",
        "print(\"Training score: \", Training[1])\n",
        "print(\"Validation score: \", Validation[1])\n",
        "\n",
        "# Test 3: X_small and y_small\n",
        "Training.append(linear_model_003.score(X_small_train, y_small_train))\n",
        "Validation.append(linear_model_003.score(X_small_val, y_small_val))\n",
        "\n",
        "print(\"Test 3: X_small and y_small\")\n",
        "print(\"Training score: \", Training[2])\n",
        "print(\"Validation score: \", Validation[2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "3a292924",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Test # Data size  Training accuracy  Validation accuracy\n",
            "0      0    262200           0.928696             0.937391\n",
            "1      1      9200           0.608406             0.613043\n",
            "2      2     13110           0.936047             0.862069\n"
          ]
        }
      ],
      "source": [
        "columns = [\"Test #\", \"Data size\", \"Training accuracy\", \"Validation accuracy\"]\n",
        "results = pd.DataFrame(columns=columns)\n",
        "size = [X.size, X_2col.size, X_small.size]\n",
        "\n",
        "for i in range(3):\n",
        "    data = {\n",
        "        columns[0]: i,\n",
        "        columns[1]: size[i],\n",
        "        columns[2]: Training[i],\n",
        "        columns[3]: Validation[i]\n",
        "    }\n",
        "\n",
        "    results = pd.concat([results, pd.DataFrame([data])], ignore_index=True)\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4427d4f",
      "metadata": {
        "id": "d4427d4f"
      },
      "source": [
        "### Questions (4 marks)\n",
        "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
        "2. In this case, what do a false positive and a false negative represent? Which one is worse?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4e5f98",
      "metadata": {},
      "source": [
        "1. Increasing data size appears to have a more significant effect on the validation accuracy. As shown for Test 1 using X and y, the validation accuracy was the highest at 94%. However, for Test 3 with a data size in between both Test 1 and Test 2, the validation accuraacy decreased to 86%. This observation can be further supported by a drop in the validation accuracy, 61%, for Test 2 with the smallest data size. Initially, increasing the data size may improve the validation accuracy as it's being evaluated on a larger and more representative dataset. At a certain dataset size, the validation accuracy will plateau and decrease which occurs because the validation set becomes more representative. This makes it harder for the model to overfit, but it also becomes harder for the model to fit the training data perfectly. This correlation however is not as clear for the training accuracy. The training accuracy for Test 1 with the largest data size was found to be 93%. However, when the data size decreased in Test 3, the training accuracy increased to 94%. However, it appears that a small data size will cause a decrease in both the training and validation accuracies. Despite that discrepancy, in most cases, as the amount of data increases, the training accuracy generally tends to increase. This is because the model has more examples to learn from which leads to better fitting of the underlying patterns in the data. At a certain point, increasing the data size will not significantly improve the training accuracy (may plateau) which can be seen in this case.\n",
        "\n",
        "2. False positive represents email that have been classified as spam when they are actually not spam. False negative represents email that have not been classified as spam but are actually spam. In this case, false positives are worse. This is because some important emails may end up being deleted/hidden/ignored by the user since they have been marked as spam. For the case of a false negative, the user may become annoyed by having their inbox cluttered with spam emails but atleast no important information will be lost by an email being classified as spam when it actually is not."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7559517a",
      "metadata": {
        "id": "7559517a"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fe687f",
      "metadata": {
        "id": "59fe687f"
      },
      "source": [
        "*DESCRIBE YOUR PROCESS HERE*\n",
        "1. I referred to the class/lab notes to determine the functions required to fit the model and predict data. I also referenced the pandas pydata website to find out how to display the type of X and y (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html). I used ChatGPT (https://chat.openai.com) to check if my loop to create the results table was correct as I had been getting an error trying to run it. Turns out, the append method had been removed.\n",
        "2. To create my code, I started from the first step and completed them in sequential order. Initially I had hardcoded the results table but added in a loop for a more efficient approach.\n",
        "3. I had only used generative AI to help with checking my loop for creating the results table. I had initially used append but that method had been removed for pandas. Thus, ChatGPT was able to provide me with the updated method, concat, to add new rows of data to the results table based on the following prompt, \"pandas.append has been removed. what is an alternative way to add a row to pandas dataframe?\". I did not use the code provided by ChatGPT. Instead, I used the method ChatGPT provided and integrated that into my code. \n",
        "4. My biggest challenge was figuring out how to create the results table using a loop. I had initially wanted to prevent creating lists for the training and validation scores but in the end, it was the method that worked the best for me. In addition, another major challenge was trying to solve the environment issues. I was unable to read in the data and thus could not begin the assignment. Using Google Collab worked but I was determined to use VSCode. Thus, I recreated a new environment and updated all package versions. This solved the issue and I was able to complete the assignment via VSCode. \n",
        "I believe that reviewing the class notes and lab material helped to ensure that there were no major challenges in completing this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4c78a8",
      "metadata": {
        "id": "fb4c78a8"
      },
      "source": [
        "## Part 2: Regression (10.5 marks total)\n",
        "\n",
        "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ba83c5",
      "metadata": {
        "id": "b2ba83c5"
      },
      "source": [
        "### Step 1: Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "6ff2e34f",
      "metadata": {
        "id": "6ff2e34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of X is: 8240\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1030 entries, 0 to 1029\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   cement  1030 non-null   float64\n",
            " 1   slag    1030 non-null   float64\n",
            " 2   ash     1030 non-null   float64\n",
            " 3   water   1030 non-null   float64\n",
            " 4   splast  1030 non-null   float64\n",
            " 5   coarse  1030 non-null   float64\n",
            " 6   fine    1030 non-null   float64\n",
            " 7   age     1030 non-null   int64  \n",
            "dtypes: float64(7), int64(1)\n",
            "memory usage: 64.5 KB\n",
            "\n",
            "The size and type of y is: 1030\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 1030 entries, 0 to 1029\n",
            "Series name: strength\n",
            "Non-Null Count  Dtype  \n",
            "--------------  -----  \n",
            "1030 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 8.2 KB\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import spam dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_concrete\n",
        "X, y = load_concrete()\n",
        "\n",
        "# TO DO: Print size and type of X and y\n",
        "print(\"The size of X is:\", X.size)\n",
        "X.info()\n",
        "# print(\"The type of X is:\", X.info())\n",
        "\n",
        "print(\"\\nThe size and type of y is:\", y.size)\n",
        "y.info()\n",
        "# print(\"The type of y is:\", y.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5294cfa",
      "metadata": {
        "id": "c5294cfa"
      },
      "source": [
        "### Step 2: Data Processing (0.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "693c5fa3",
      "metadata": {
        "id": "693c5fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in X:\n",
            "cement    0\n",
            "slag      0\n",
            "ash       0\n",
            "water     0\n",
            "splast    0\n",
            "coarse    0\n",
            "fine      0\n",
            "age       0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in y: 0\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "print(\"Missing values in X:\")\n",
        "print(X.isna().sum())\n",
        "print(\"\\nMissing values in y:\", y.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc60489",
      "metadata": {
        "id": "1bc60489"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model (1 mark)\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "b5041945",
      "metadata": {
        "id": "b5041945"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
        "lr = LinearRegression().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1de28482",
      "metadata": {
        "id": "1de28482"
      },
      "source": [
        "### Step 4: Validate Model (1 mark)\n",
        "\n",
        "Calculate the training and validation accuracy using mean squared error and R2 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "970c038b",
      "metadata": {
        "id": "970c038b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy using MSE and R2: 111.35843861132467 , 0.6108229424520555\n",
            "Validation accuracy using MSE and R2: 95.90413603680645 , 0.6234144623633329\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "y_pred_train = lr.predict(X_train)\n",
        "y_pred_val = lr.predict(X_val)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_val = mean_squared_error(y_val, y_pred_val)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "r2_val = r2_score(y_val, y_pred_val)\n",
        "\n",
        "print(\"Training accuracy using MSE and R2:\", mse_train, \",\", r2_train)\n",
        "print(\"Validation accuracy using MSE and R2:\", mse_val, \",\", r2_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aa7795",
      "metadata": {
        "id": "54aa7795"
      },
      "source": [
        "### Step 5: Visualize Results (1 mark)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "88d223f3",
      "metadata": {
        "id": "88d223f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Training accuracy</th>\n",
              "      <th>Validation accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MSE</td>\n",
              "      <td>111.358439</td>\n",
              "      <td>95.904136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R2</td>\n",
              "      <td>0.610823</td>\n",
              "      <td>0.623414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Index  Training accuracy  Validation accuracy\n",
              "0   MSE         111.358439            95.904136\n",
              "1    R2           0.610823             0.623414"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "results = pd.DataFrame()\n",
        "results['Index'] = ['MSE', 'R2']\n",
        "results['Training accuracy'] = [mse_train, r2_train]\n",
        "results['Validation accuracy'] = [mse_val, r2_val]\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a42bda",
      "metadata": {
        "id": "70a42bda"
      },
      "source": [
        "### Questions (2 marks)\n",
        "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
        "\n",
        "I don't believe the linear model produced great results for this dataset. Looking at the R2 score, we would want that value to be as close to 1.0 as possible. However, for this dataset, the highest R2 value was only 0.62. Having a R2 score near 1.0 would indicate that the model is able to accurately predict the outcome of the dependable variables/features. Typically, if the R2 value for the training set is higher than the R2 score of the validation set, the model is overfitted. Since the R2 score for the validation set is slightly higher than the training, it could indicate that the model has not been overfitted and with a larger dataset, the validation R2 score could increase furthher.\n",
        "\n",
        "For the mean squared error value, a larger MSE indicates that the predicted data are dispersed widely from the expected results, whereas a smaller MSE suggests the opposite. A smaller MSE is preferred because it indicates that your data points are were predicted to be more similar to the known outcome. The MSE is the average of all of the squared differences between the true values and the predicted values. Our goal is to select the model where the test MSE is lowest across choices of other models.\n",
        "\n",
        "In addition, the dataset states that the concrete compressive strength (target) is a highly nonlinear function of age and ingredients. Based on this, it is reasonable to assume that a linear model would not be the best model to train to predict the target. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca0ff2f",
      "metadata": {
        "id": "2ca0ff2f"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdb0880",
      "metadata": {
        "id": "dfdb0880"
      },
      "source": [
        "*DESCRIBE YOUR PROCESS HERE*\n",
        "1. To determine the mean squared error and r2 score, I had to refer to the scikit-learn.org website to find the appropriate methods (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html and https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html). Similar to part 1, I had referred to the class and lab notes to reference which methods are required to fit and test the model.\n",
        "2. Similar to part 1, I had completed the steps in sequential order. Most of the steps required the previous step to be completed or else it would be difficult to complete the next steps. \n",
        "3. No generative AI was used for this part of the assignment.\n",
        "4. The biggest challenge for this part of the assisngment was interpreting the results. I had to refer to the class notes to determine the significance of the MSE and R2 score values. In addition, no loop was used for the results table for this part of the assignment since the results table is so small. Similar to the previous part, reviewing the course material was integral to ensuring no major challenges arose. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72ac3eb",
      "metadata": {
        "id": "e72ac3eb"
      },
      "source": [
        "## Part 3: Observations/Interpretation (3 marks)\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "*ADD YOUR FINDINGS HERE*\n",
        "\n",
        "Since MSE is a measure of the average squared difference between the actual (observed) values and the predicted values generated by the linear regression model, a lower MSE would indicate a better fit of the model to the data. MSE serves as a way to quantify how well the model's predictions match the actual data. In other words, smaller MSE values imply that the model's predictions are closer to the actual values, while larger MSE values indicate a poorer fit. \n",
        "\n",
        "On the other hand, the R2 score represents the variance proportion in the target which can be explained by the features used in the linear regression model (e.g., the goodness of the fit of the linear regression model). The R2 score ranges from 0 to 1, with 1 being an ideal model fitted to the dataset. An R2 score of 0 indicates that the model doesn't explain any variance, while an R2 score of 1 indicates a perfect fit where the model perfectly predicts the target variable.\n",
        "\n",
        "As observed in the results from the model, a higher R2 score was observed for a lower MSE score (e.g., MSE of 111.36 had an associated R2 score of 0.61 whereas an MSE of 95.9 had an associated R2 score of 0.62.) This is expected as a lower MSE indicates that the predicted values deviated less from the target values. With regards to the R2 score, a higher score indicates a better fitted model to the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b84eed",
      "metadata": {
        "id": "40b84eed"
      },
      "source": [
        "## Part 4: Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "*ADD YOUR THOUGHTS HERE*\n",
        "- I enjoyed having the opportunity to working through examples from start to finish. It was usefult to reinforce the material learned in class and during the lab sessions.\n",
        "- I found the results to be interesting but confusing at the same time. Getting results that weren't quite as expected was helpful in getting me to try to understand why these particular results were observed. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db951b3a",
      "metadata": {
        "id": "db951b3a"
      },
      "source": [
        "## Part 5: Bonus Question (4 marks)\n",
        "\n",
        "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
        "\n",
        "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "47623d44",
      "metadata": {
        "id": "47623d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge Regression with alpha = 0.001\n",
            "Mean Squared Error: 95.97547158704613\n",
            "R-squared (R2): 0.627541655086022\n",
            "\n",
            "Ridge Regression with alpha = 1.0\n",
            "Mean Squared Error: 95.96966712154402\n",
            "R-squared (R2): 0.6275641808582665\n",
            "\n",
            "Ridge Regression with alpha = 100.0\n",
            "Mean Squared Error: 101.81240449751492\n",
            "R-squared (R2): 0.6048898844277723\n",
            "\n",
            "Ridge Regression with alpha = 10.0\n",
            "Mean Squared Error: 96.27676054442806\n",
            "R-squared (R2): 0.6263724231504898\n",
            "\n",
            "Lasso Regression with alpha = 0.001\n",
            "Mean Squared Error: 95.9746068931565\n",
            "R-squared (R2): 0.6275450107606507\n",
            "\n",
            "Lasso Regression with alpha = 0.1\n",
            "Mean Squared Error: 96.41516117745807\n",
            "R-squared (R2): 0.6258353226824118\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "\n",
        "# RIDGE REGRESSION\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X, y = load_concrete()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "ridge_model_1 = Ridge(alpha=0.001)\n",
        "ridge_model_1.fit(X_train, y_train)\n",
        "\n",
        "y_pred_1 = ridge_model_1.predict(X_test)\n",
        "\n",
        "mse_1 = mean_squared_error(y_test, y_pred_1)\n",
        "r2_1 = r2_score(y_test, y_pred_1)\n",
        "\n",
        "print(\"Ridge Regression with alpha = 0.001\")\n",
        "print(f\"Mean Squared Error: {mse_1}\")\n",
        "print(f\"R-squared (R2): {r2_1}\")\n",
        "\n",
        "ridge_model_2 = Ridge(alpha=1.0)\n",
        "ridge_model_2.fit(X_train, y_train)\n",
        "\n",
        "y_pred_2 = ridge_model_2.predict(X_test)\n",
        "\n",
        "mse_2 = mean_squared_error(y_test, y_pred_2)\n",
        "r2_2 = r2_score(y_test, y_pred_2)\n",
        "\n",
        "print(\"\\nRidge Regression with alpha = 1.0\")\n",
        "print(f\"Mean Squared Error: {mse_2}\")\n",
        "print(f\"R-squared (R2): {r2_2}\")\n",
        "\n",
        "ridge_model_3 = Ridge(alpha=100.0)\n",
        "ridge_model_3.fit(X_train, y_train)\n",
        "\n",
        "y_pred_3 = ridge_model_3.predict(X_test)\n",
        "\n",
        "mse_3 = mean_squared_error(y_test, y_pred_3)\n",
        "r2_3 = r2_score(y_test, y_pred_3)\n",
        "\n",
        "print(\"\\nRidge Regression with alpha = 100.0\")\n",
        "print(f\"Mean Squared Error: {mse_3}\")\n",
        "print(f\"R-squared (R2): {r2_3}\")\n",
        "\n",
        "ridge_model_4 = Ridge(alpha=10.0)\n",
        "ridge_model_4.fit(X_train, y_train)\n",
        "\n",
        "y_pred_4 = ridge_model_4.predict(X_test)\n",
        "\n",
        "mse_4 = mean_squared_error(y_test, y_pred_4)\n",
        "r2_4 = r2_score(y_test, y_pred_4)\n",
        "\n",
        "print(\"\\nRidge Regression with alpha = 10.0\")\n",
        "print(f\"Mean Squared Error: {mse_4}\")\n",
        "print(f\"R-squared (R2): {r2_4}\")\n",
        "\n",
        "\n",
        "# LASSO REGRESSION\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_model_1 = Lasso(alpha=0.001)\n",
        "lasso_model_1.fit(X_train, y_train)\n",
        "y_pred_l1 = lasso_model_1.predict(X_test)\n",
        "\n",
        "mse_l1 = mean_squared_error(y_test, y_pred_l1)\n",
        "r2_l1 = r2_score(y_test, y_pred_l1)\n",
        "\n",
        "print(\"\\nLasso Regression with alpha = 0.001\")\n",
        "print(f\"Mean Squared Error: {mse_l1}\")\n",
        "print(f\"R-squared (R2): {r2_l1}\")\n",
        "\n",
        "lasso_model_2 = Lasso(alpha=0.1)\n",
        "lasso_model_2.fit(X_train, y_train)\n",
        "y_pred_l2 = lasso_model_2.predict(X_test)\n",
        "\n",
        "mse_l2 = mean_squared_error(y_test, y_pred_l2)\n",
        "r2_l2 = r2_score(y_test, y_pred_l2)\n",
        "\n",
        "print(\"\\nLasso Regression with alpha = 0.1\")\n",
        "print(f\"Mean Squared Error: {mse_l2}\")\n",
        "print(f\"R-squared (R2): {r2_l2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b606236",
      "metadata": {
        "id": "1b606236"
      },
      "source": [
        "*ANSWER HERE*\n",
        "Both methods gave very similar results. At higher values of alpha, more coefficients are driven to zero (Lasso) or be small (Ridge) resulting in only retaining the most important features in the model. Thus, the model becomes simpler and less prone to overfitting. However, the model could underfit the data if the regularization is too strong. A smaller alpha value indicates less coefficients to be driven to zero or minimzed thus, resulting in a more complicated model. \n",
        "\n",
        "In both cases, the R2 score is not really acceptable as the value is quite far from the desired value near 1.0. This R2 value indicates that the model is only able to predict the correct values ~63% of the time."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
